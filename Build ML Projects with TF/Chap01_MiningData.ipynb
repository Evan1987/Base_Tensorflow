{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Show and Save Data Flow Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node {\n",
      "  name: \"zeros\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_FLOAT\n",
      "        tensor_shape {\n",
      "          dim {\n",
      "            size: 10\n",
      "          }\n",
      "          dim {\n",
      "            size: 5\n",
      "          }\n",
      "        }\n",
      "        float_val: 0.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"Variable\"\n",
      "  op: \"VariableV2\"\n",
      "  attr {\n",
      "    key: \"container\"\n",
      "    value {\n",
      "      s: \"\"\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"shape\"\n",
      "    value {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 10\n",
      "        }\n",
      "        dim {\n",
      "          size: 5\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"shared_name\"\n",
      "    value {\n",
      "      s: \"\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"Variable/Assign\"\n",
      "  op: \"Assign\"\n",
      "  input: \"Variable\"\n",
      "  input: \"zeros\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@Variable\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"use_locking\"\n",
      "    value {\n",
      "      b: true\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"validate_shape\"\n",
      "    value {\n",
      "      b: true\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"Variable/read\"\n",
      "  op: \"Identity\"\n",
      "  input: \"Variable\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_class\"\n",
      "    value {\n",
      "      list {\n",
      "        s: \"loc:@Variable\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"Placeholder\"\n",
      "  op: \"Placeholder\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"shape\"\n",
      "    value {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: 10\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"MatMul\"\n",
      "  op: \"MatMul\"\n",
      "  input: \"Placeholder\"\n",
      "  input: \"Variable/read\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"transpose_a\"\n",
      "    value {\n",
      "      b: false\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"transpose_b\"\n",
      "    value {\n",
      "      b: false\n",
      "    }\n",
      "  }\n",
      "}\n",
      "versions {\n",
      "  producer: 24\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    sess = tf.Session()\n",
    "    W = tf.Variable(tf.zeros(shape=[10, 5]))\n",
    "    x = tf.placeholder(dtype=tf.float32, shape=[None, 10])\n",
    "    result = tf.matmul(x, W)\n",
    "    ## writer = tf.summary.FileWriter(\"/Users/lixing/board/chap01\", g)\n",
    "    ## writer.close()\n",
    "    ### exec tensorboard --logdir=/Users/lixing/board/chap01 on terminal\n",
    "    print(g.as_graph_def())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Simple Matrix Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "## int32 4*4 matrix\n",
    "X = tf.constant([[2, 5, 3, -5], \n",
    "                 [0, 3, -2, 5], \n",
    "                 [4, 3, 5, 3], \n",
    "                 [6, 1, 4, 0]])\n",
    "## int32 4*5 matrix\n",
    "Y = tf.constant([[4, -7, 4, -3, 4], \n",
    "                 [6, 4, -7, 4, 7], \n",
    "                 [2, 3, 2, 1, 4], \n",
    "                 [1, 5, 5, 5, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## change dtype of a tensor\n",
    "floatX = tf.cast(X, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  0,  4,  6],\n",
       "       [ 5,  3,  3,  1],\n",
       "       [ 3, -2,  5,  4],\n",
       "       [-5,  5,  3,  0]], dtype=int32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.transpose(X).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 39, -10, -46,  -8,  45],\n",
       "       [ 19,  31,   0,  35,  23],\n",
       "       [ 47,  14,  20,  20,  63],\n",
       "       [ 38, -26,  25, -10,  47]], dtype=int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 矩阵乘法\n",
    "tf.matmul(X, Y).eval()\n",
    "## same as (X @ Y).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "817.9997"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 矩阵行列式\n",
    "tf.matrix_determinant(floatX).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00855745,  0.10513447, -0.18948655,  0.29584354],\n",
       "       [ 0.12958434,  0.12224938,  0.01222495, -0.05134475],\n",
       "       [-0.01955992, -0.18826404,  0.2811736 , -0.1809291 ],\n",
       "       [-0.08557458,  0.05134474,  0.10513448, -0.0415648 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 矩阵的逆\n",
    "tf.matrix_inverse(floatX).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.0000002e+00,  8.9406967e-08,  1.1920929e-07,  0.0000000e+00],\n",
       "       [-2.9802322e-08,  1.0000000e+00,  0.0000000e+00,  4.4703484e-08],\n",
       "       [-1.1920929e-07, -8.9406967e-08,  9.9999988e-01,  1.7881393e-07],\n",
       "       [-2.9802322e-08, -3.3527613e-08, -4.4703484e-08,  1.0000000e+00]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tf.matrix_inverse(floatX) @ floatX).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.202934  ],\n",
       "       [ 0.21271393],\n",
       "       [-0.10757945],\n",
       "       [ 0.02933985]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 解线性方程组\n",
    "rhs = [[1], [1], [1], [1]]\n",
    "tf.matrix_solve(floatX, rhs).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 约减（Reduction）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# int32 3*3 matrix\n",
    "X = tf.constant([[1, 2, 3], \n",
    "                 [3, 2, 1], \n",
    "                 [-1, -2, -3]])\n",
    "# bool 3*3 matrix\n",
    "boolean_tensor = tf.constant([[True, False, True], \n",
    "                              [False, False, True], \n",
    "                              [True, False, False]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6,  6, -6], dtype=int32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_prod(X, axis=1).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3, -8, -9], dtype=int32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_prod(X, axis=0).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1, -3], dtype=int32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_min(X, axis=1).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_all(boolean_tensor, axis=1).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_any(boolean_tensor, axis=0).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 分割（segment）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "tens1 = tf.constant([[2, 5, 3, -5], \n",
    "                     [0, 3, -2, 5], \n",
    "                     [4, 3, 5, 3], \n",
    "                     [6, 1, 4, 0], \n",
    "                     [6, 1, 4, 0]])\n",
    "## segment ids 给出的是组号，也是最后输出对应的行号，长度一定与tens1的行数相等\n",
    "## segment ids must be increasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  5,  3, -5],\n",
       "       [ 4,  6,  3,  8],\n",
       "       [ 0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0],\n",
       "       [12,  2,  8,  0]], dtype=int32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_ids = tf.constant([0, 1, 1, 4, 4])\n",
    "tf.segment_sum(tens1, seg_ids).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  5,  3, -5],\n",
       "       [ 4,  6,  3,  8],\n",
       "       [12,  2,  8,  0]], dtype=int32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_ids = tf.constant([0, 1, 1, 2, 2])\n",
    "tf.segment_sum(tens1, seg_ids).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  5,  3, -5],\n",
       "       [ 2,  3,  1,  4],\n",
       "       [ 6,  1,  4,  0]], dtype=int32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_ids = tf.constant([0, 1, 1, 2, 2])\n",
    "tf.segment_mean(tens1, seg_ids).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  5,  3, -5],\n",
       "       [ 4,  3,  5,  5],\n",
       "       [ 6,  1,  4,  0]], dtype=int32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_ids = tf.constant([0, 1, 1, 2, 2])\n",
    "tf.segment_max(tens1, seg_ids).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([[2, 5, 3, -5], \n",
    "                 [0, 3, -2, 5], \n",
    "                 [4, 3, 5, 3], \n",
    "                 [6, 1, 4, 0]])\n",
    "listx = tf.constant(np.arange(1, 9), dtype=tf.int32)\n",
    "listy = tf.constant([4, 5, 8, 9], dtype=tf.int32)\n",
    "boolx = tf.constant([[True, False], [False, True]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 1, 3])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.argmin(x, axis=1).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 6 7]\n",
      "[0 1 2 5 6]\n"
     ]
    }
   ],
   "source": [
    "diff_elements, diff_indexes_of_x = tf.setdiff1d(listx, listy)\n",
    "print(diff_elements.eval())\n",
    "print(diff_indexes_of_x.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 3],\n",
       "       [2, 0],\n",
       "       [2, 2],\n",
       "       [3, 0],\n",
       "       [3, 2]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.where(x > 3).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.where(boolx).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6 7 8]\n",
      "[0 1 2 3 4 5 6 7]\n"
     ]
    }
   ],
   "source": [
    "elements, indexes = tf.unique(listx)\n",
    "print(elements.eval())\n",
    "print(indexes.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 形状变换  切片 连接 填充 打包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([[2, 5, 3, -5], \n",
    "                 [0, 3, -2, 5], \n",
    "                 [4, 3, 5, 3], \n",
    "                 [6, 1, 4, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4], dtype=int32)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.shape(x).eval()\n",
    "## x.shape.as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.size(x).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.rank(x).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  5],\n",
       "       [ 3, -5],\n",
       "       [ 0,  3],\n",
       "       [-2,  5],\n",
       "       [ 4,  3],\n",
       "       [ 5,  3],\n",
       "       [ 6,  1],\n",
       "       [ 4,  0]], dtype=int32)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(x, [8, 2]).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2 3]]\n",
      "[0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([[0,1,2,3]])\n",
    "print(a.eval())\n",
    "print(tf.squeeze(a).eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 2,  5,  3, -5]],\n",
       "\n",
       "       [[ 0,  3, -2,  5]],\n",
       "\n",
       "       [[ 4,  3,  5,  3]],\n",
       "\n",
       "       [[ 6,  1,  4,  0]]], dtype=int32)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims(x, axis=1).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [[1 2 3]\n",
    "# [4 5 6]\n",
    "# [7 8 9]]\n",
    "t_matrix = tf.reshape(tf.constant(np.arange(1, 10)), [3, 3])\n",
    "t_array = tf.constant([1, 2, 3, 4, 9, 8, 6, 5])\n",
    "t_array2 = tf.constant([2, 3, 4, 5, 6, 7, 8, 9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 6],\n",
       "       [8, 9]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.slice(t_matrix, begin=[1, 1], size=[2, 2]).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n",
      "[9 8 6 5]\n"
     ]
    }
   ],
   "source": [
    "t1, t2 = tf.split(t_array, 2)  ## split 必须是等分\n",
    "print(t1.eval())\n",
    "print(t2.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 2, 1, 2], dtype=int32)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.tile([1, 2], [3]).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0],\n",
       "       [1, 2, 3, 0],\n",
       "       [4, 5, 6, 0],\n",
       "       [7, 8, 9, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.pad(t_matrix, paddings=[[1, 2], [0, 1]]).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 9 8 6 5 2 3 4 5 6 7 8 9]\n",
      "[[1 2 3 4 9 8 6 5]\n",
      " [2 3 4 5 6 7 8 9]]\n"
     ]
    }
   ],
   "source": [
    "print(tf.concat([t_array, t_array2], axis=0).eval())\n",
    "print(tf.concat([tf.reshape(t_array, [1, -1]), tf.reshape(t_array2, [1, -1])], axis=0).eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3 4 9 8 6 5]\n",
      " [2 3 4 5 6 7 8 9]]\n",
      "[[1 2]\n",
      " [2 3]\n",
      " [3 4]\n",
      " [4 5]\n",
      " [9 6]\n",
      " [8 7]\n",
      " [6 8]\n",
      " [5 9]]\n"
     ]
    }
   ],
   "source": [
    "print(tf.stack([t_array, t_array2], axis=0).eval())\n",
    "print(tf.stack([t_array, t_array2], axis=1).eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1, 2, 3]), array([4, 5, 6]), array([7, 8, 9])]\n",
      "[array([1, 4, 7]), array([2, 5, 8]), array([3, 6, 9])]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(tf.unstack(t_matrix, axis=0)))\n",
    "print(sess.run(tf.unstack(t_matrix, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 2, 1],\n",
       "       [6, 5, 4],\n",
       "       [9, 8, 7]])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reverse(t_matrix, axis=tf.constant([1])).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7, 8, 9],\n",
       "       [4, 5, 6],\n",
       "       [1, 2, 3]])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reverse(t_matrix, axis=tf.constant([0])).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9, 8, 7],\n",
       "       [6, 5, 4],\n",
       "       [3, 2, 1]])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reverse(t_matrix, axis=tf.constant([0, 1])).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## csv\n",
    "file_path = \"/Users/lixing/jupyter/Build ML Projects with TF/Chap01_bak/iris.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_queue):\n",
    "    reader = tf.TextLineReader(skip_header_lines=1)\n",
    "    key, value = reader.read(file_queue)\n",
    "    record_defaults = [[''], [''], [''], [''], ['']]\n",
    "    SepalLength, SepalWidth, PetalLength, PetalWidth, Species = tf.decode_csv(value, record_defaults)\n",
    "    process_op = tf.case({\n",
    "        tf.equal(Species, tf.constant(\"setosa\")): lambda : tf.constant(1), \n",
    "        tf.equal(Species, tf.constant(\"versicolor\")): lambda : tf.constant(2), \n",
    "        tf.equal(Species, tf.constant(\"virginica\")): lambda : tf.constant(3)}, \n",
    "        default=lambda : tf.constant(-1), exclusive=True)\n",
    "    dat = tf.stack([SepalLength, SepalWidth, PetalLength, PetalWidth, Species], axis=0)\n",
    "    return dat, process_op\n",
    "\n",
    "def create_pipeline(file_path, batch_size, num_epochs=None):\n",
    "    file_queue = tf.train.string_input_producer(\n",
    "        tf.train.match_filenames_once(file_path), \n",
    "        shuffle=True,\n",
    "        num_epochs=num_epochs)\n",
    "    example, label = read_data(file_queue)\n",
    "    min_after_dequeue = 1000\n",
    "    capacity = min_after_dequeue + batch_size\n",
    "    example_batch, label_batch = tf.train.shuffle_batch(\n",
    "        [example, label], \n",
    "        batch_size=batch_size, \n",
    "        capacity=capacity,\n",
    "        min_after_dequeue=min_after_dequeue)\n",
    "    return example_batch, label_batch\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = create_pipeline(file_path, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[b'5.8' b'2.7' b'3.9' b'1.2' b'versicolor']\n",
      " [b'5.6' b'3' b'4.5' b'1.5' b'versicolor']\n",
      " [b'5.6' b'2.7' b'4.2' b'1.3' b'versicolor']\n",
      " [b'5.7' b'4.4' b'1.5' b'0.4' b'setosa']\n",
      " [b'4.4' b'2.9' b'1.4' b'0.2' b'setosa']\n",
      " [b'4.8' b'3' b'1.4' b'0.3' b'setosa']\n",
      " [b'5.7' b'3.8' b'1.7' b'0.3' b'setosa']\n",
      " [b'5.7' b'2.9' b'4.2' b'1.3' b'versicolor']\n",
      " [b'4.8' b'3.4' b'1.6' b'0.2' b'setosa']\n",
      " [b'7.2' b'3.2' b'6' b'1.8' b'virginica']\n",
      " [b'5.1' b'3.5' b'1.4' b'0.3' b'setosa']\n",
      " [b'6.4' b'3.2' b'4.5' b'1.5' b'versicolor']\n",
      " [b'6.4' b'2.9' b'4.3' b'1.3' b'versicolor']\n",
      " [b'4.8' b'3' b'1.4' b'0.3' b'setosa']\n",
      " [b'6.5' b'3' b'5.2' b'2' b'virginica']\n",
      " [b'5.1' b'3.5' b'1.4' b'0.3' b'setosa']\n",
      " [b'5.1' b'3.7' b'1.5' b'0.4' b'setosa']\n",
      " [b'6.4' b'2.8' b'5.6' b'2.2' b'virginica']\n",
      " [b'6.7' b'3' b'5.2' b'2.3' b'virginica']\n",
      " [b'5' b'2.3' b'3.3' b'1' b'versicolor']\n",
      " [b'5.7' b'2.6' b'3.5' b'1' b'versicolor']\n",
      " [b'5.6' b'3' b'4.5' b'1.5' b'versicolor']\n",
      " [b'5.7' b'3' b'4.2' b'1.2' b'versicolor']\n",
      " [b'6.5' b'2.8' b'4.6' b'1.5' b'versicolor']\n",
      " [b'5.4' b'3.4' b'1.7' b'0.2' b'setosa']\n",
      " [b'6.8' b'2.8' b'4.8' b'1.4' b'versicolor']\n",
      " [b'4.9' b'3' b'1.4' b'0.2' b'setosa']\n",
      " [b'6.4' b'2.9' b'4.3' b'1.3' b'versicolor']\n",
      " [b'5.4' b'3.9' b'1.7' b'0.4' b'setosa']\n",
      " [b'6.3' b'2.8' b'5.1' b'1.5' b'virginica']\n",
      " [b'6.9' b'3.1' b'5.1' b'2.3' b'virginica']\n",
      " [b'5.9' b'3' b'5.1' b'1.8' b'virginica']\n",
      " [b'4.6' b'3.4' b'1.4' b'0.3' b'setosa']\n",
      " [b'5.5' b'2.4' b'3.8' b'1.1' b'versicolor']\n",
      " [b'4.8' b'3' b'1.4' b'0.3' b'setosa']\n",
      " [b'5.8' b'2.7' b'5.1' b'1.9' b'virginica']\n",
      " [b'4.9' b'3.1' b'1.5' b'0.2' b'setosa']\n",
      " [b'5.1' b'3.8' b'1.6' b'0.2' b'setosa']\n",
      " [b'5.5' b'2.6' b'4.4' b'1.2' b'versicolor']\n",
      " [b'5.6' b'3' b'4.5' b'1.5' b'versicolor']\n",
      " [b'7.7' b'3.8' b'6.7' b'2.2' b'virginica']\n",
      " [b'6.2' b'3.4' b'5.4' b'2.3' b'virginica']\n",
      " [b'6.3' b'2.5' b'4.9' b'1.5' b'versicolor']\n",
      " [b'4.8' b'3.1' b'1.6' b'0.2' b'setosa']\n",
      " [b'5.5' b'2.5' b'4' b'1.3' b'versicolor']\n",
      " [b'5.1' b'3.3' b'1.7' b'0.5' b'setosa']\n",
      " [b'6.5' b'3' b'5.8' b'2.2' b'virginica']\n",
      " [b'6' b'2.2' b'4' b'1' b'versicolor']\n",
      " [b'7.4' b'2.8' b'6.1' b'1.9' b'virginica']\n",
      " [b'5' b'3.3' b'1.4' b'0.2' b'setosa']\n",
      " [b'6' b'2.9' b'4.5' b'1.5' b'versicolor']\n",
      " [b'6.3' b'2.7' b'4.9' b'1.8' b'virginica']\n",
      " [b'6.4' b'3.1' b'5.5' b'1.8' b'virginica']\n",
      " [b'6.4' b'2.9' b'4.3' b'1.3' b'versicolor']\n",
      " [b'6' b'2.9' b'4.5' b'1.5' b'versicolor']\n",
      " [b'5.7' b'2.8' b'4.1' b'1.3' b'versicolor']\n",
      " [b'4.8' b'3' b'1.4' b'0.1' b'setosa']\n",
      " [b'5.8' b'2.6' b'4' b'1.2' b'versicolor']\n",
      " [b'5.7' b'3.8' b'1.7' b'0.3' b'setosa']\n",
      " [b'5.8' b'2.6' b'4' b'1.2' b'versicolor']]\n",
      "[2 2 2 1 1 1 1 2 1 3 1 2 2 1 3 1 1 3 3 2 2 2 2 2 1 2 1 2 1 3 3 3 1 2 1 3 1\n",
      " 1 2 2 3 3 2 1 2 1 3 2 3 1 2 3 3 2 2 2 1 2 1 2]\n",
      "[[b'6.7' b'3.3' b'5.7' b'2.5' b'virginica']\n",
      " [b'6.7' b'3.3' b'5.7' b'2.1' b'virginica']\n",
      " [b'6.3' b'3.3' b'4.7' b'1.6' b'versicolor']\n",
      " [b'7.2' b'3.6' b'6.1' b'2.5' b'virginica']\n",
      " [b'5.4' b'3.9' b'1.7' b'0.4' b'setosa']\n",
      " [b'5.7' b'2.5' b'5' b'2' b'virginica']\n",
      " [b'4.8' b'3' b'1.4' b'0.3' b'setosa']\n",
      " [b'6.9' b'3.2' b'5.7' b'2.3' b'virginica']\n",
      " [b'6.4' b'3.1' b'5.5' b'1.8' b'virginica']\n",
      " [b'4.9' b'3.6' b'1.4' b'0.1' b'setosa']\n",
      " [b'6.3' b'2.5' b'5' b'1.9' b'virginica']\n",
      " [b'5.1' b'3.5' b'1.4' b'0.2' b'setosa']\n",
      " [b'4.4' b'3' b'1.3' b'0.2' b'setosa']\n",
      " [b'6.7' b'3.1' b'4.7' b'1.5' b'versicolor']\n",
      " [b'5.6' b'3' b'4.1' b'1.3' b'versicolor']\n",
      " [b'6.3' b'2.3' b'4.4' b'1.3' b'versicolor']\n",
      " [b'4.6' b'3.4' b'1.4' b'0.3' b'setosa']\n",
      " [b'5.4' b'3.4' b'1.5' b'0.4' b'setosa']\n",
      " [b'6.4' b'2.8' b'5.6' b'2.1' b'virginica']\n",
      " [b'6.3' b'3.3' b'6' b'2.5' b'virginica']\n",
      " [b'5.5' b'2.4' b'3.7' b'1' b'versicolor']\n",
      " [b'6.3' b'3.3' b'6' b'2.5' b'virginica']\n",
      " [b'7.6' b'3' b'6.6' b'2.1' b'virginica']\n",
      " [b'4.4' b'3' b'1.3' b'0.2' b'setosa']\n",
      " [b'5.7' b'2.8' b'4.5' b'1.3' b'versicolor']\n",
      " [b'5.4' b'3.4' b'1.7' b'0.2' b'setosa']\n",
      " [b'5.7' b'2.9' b'4.2' b'1.3' b'versicolor']\n",
      " [b'4.9' b'3.1' b'1.5' b'0.2' b'setosa']\n",
      " [b'4.8' b'3.4' b'1.9' b'0.2' b'setosa']\n",
      " [b'5.8' b'2.8' b'5.1' b'2.4' b'virginica']\n",
      " [b'5.4' b'3.4' b'1.7' b'0.2' b'setosa']\n",
      " [b'5.2' b'4.1' b'1.5' b'0.1' b'setosa']\n",
      " [b'6.3' b'3.3' b'4.7' b'1.6' b'versicolor']\n",
      " [b'4.8' b'3' b'1.4' b'0.1' b'setosa']\n",
      " [b'5' b'3.3' b'1.4' b'0.2' b'setosa']\n",
      " [b'4.8' b'3.4' b'1.9' b'0.2' b'setosa']\n",
      " [b'5.9' b'3' b'5.1' b'1.8' b'virginica']\n",
      " [b'6.1' b'2.9' b'4.7' b'1.4' b'versicolor']\n",
      " [b'4.4' b'2.9' b'1.4' b'0.2' b'setosa']\n",
      " [b'6.5' b'2.8' b'4.6' b'1.5' b'versicolor']\n",
      " [b'6' b'2.2' b'5' b'1.5' b'virginica']\n",
      " [b'4.8' b'3' b'1.4' b'0.1' b'setosa']\n",
      " [b'5.9' b'3' b'4.2' b'1.5' b'versicolor']\n",
      " [b'6.7' b'3' b'5' b'1.7' b'versicolor']\n",
      " [b'4.9' b'3.1' b'1.5' b'0.2' b'setosa']\n",
      " [b'4.6' b'3.4' b'1.4' b'0.3' b'setosa']\n",
      " [b'7.6' b'3' b'6.6' b'2.1' b'virginica']\n",
      " [b'6' b'2.7' b'5.1' b'1.6' b'versicolor']\n",
      " [b'7.2' b'3.6' b'6.1' b'2.5' b'virginica']\n",
      " [b'4.9' b'2.5' b'4.5' b'1.7' b'virginica']\n",
      " [b'6.8' b'2.8' b'4.8' b'1.4' b'versicolor']\n",
      " [b'4.9' b'2.5' b'4.5' b'1.7' b'virginica']\n",
      " [b'6.1' b'2.6' b'5.6' b'1.4' b'virginica']\n",
      " [b'5.2' b'4.1' b'1.5' b'0.1' b'setosa']\n",
      " [b'4.3' b'3' b'1.1' b'0.1' b'setosa']\n",
      " [b'6.2' b'2.2' b'4.5' b'1.5' b'versicolor']\n",
      " [b'6.1' b'2.8' b'4.7' b'1.2' b'versicolor']\n",
      " [b'6.7' b'3.1' b'4.7' b'1.5' b'versicolor']\n",
      " [b'6.7' b'3.1' b'5.6' b'2.4' b'virginica']\n",
      " [b'5.1' b'3.7' b'1.5' b'0.4' b'setosa']]\n",
      "[3 3 2 3 1 3 1 3 3 1 3 1 1 2 2 2 1 1 3 3 2 3 3 1 2 1 2 1 1 3 1 1 2 1 1 1 3\n",
      " 2 1 2 3 1 2 2 1 1 3 2 3 3 2 3 3 1 1 2 2 2 3 1]\n",
      "[[b'5.6' b'2.5' b'3.9' b'1.1' b'versicolor']\n",
      " [b'5.6' b'2.8' b'4.9' b'2' b'virginica']\n",
      " [b'4.9' b'2.5' b'4.5' b'1.7' b'virginica']\n",
      " [b'7' b'3.2' b'4.7' b'1.4' b'versicolor']\n",
      " [b'4.4' b'3.2' b'1.3' b'0.2' b'setosa']\n",
      " [b'5.7' b'2.8' b'4.5' b'1.3' b'versicolor']\n",
      " [b'4.5' b'2.3' b'1.3' b'0.3' b'setosa']\n",
      " [b'5.4' b'3' b'4.5' b'1.5' b'versicolor']\n",
      " [b'7.4' b'2.8' b'6.1' b'1.9' b'virginica']\n",
      " [b'4.5' b'2.3' b'1.3' b'0.3' b'setosa']\n",
      " [b'7.7' b'2.6' b'6.9' b'2.3' b'virginica']\n",
      " [b'6.3' b'2.8' b'5.1' b'1.5' b'virginica']\n",
      " [b'4.6' b'3.6' b'1' b'0.2' b'setosa']\n",
      " [b'4.5' b'2.3' b'1.3' b'0.3' b'setosa']\n",
      " [b'5.9' b'3' b'5.1' b'1.8' b'virginica']\n",
      " [b'5' b'3.4' b'1.5' b'0.2' b'setosa']\n",
      " [b'6.7' b'3.1' b'4.7' b'1.5' b'versicolor']\n",
      " [b'5.6' b'3' b'4.1' b'1.3' b'versicolor']\n",
      " [b'6.6' b'2.9' b'4.6' b'1.3' b'versicolor']\n",
      " [b'6.1' b'2.9' b'4.7' b'1.4' b'versicolor']\n",
      " [b'7.4' b'2.8' b'6.1' b'1.9' b'virginica']\n",
      " [b'5.8' b'2.8' b'5.1' b'2.4' b'virginica']\n",
      " [b'5.5' b'4.2' b'1.4' b'0.2' b'setosa']\n",
      " [b'4.8' b'3' b'1.4' b'0.1' b'setosa']\n",
      " [b'5.5' b'2.4' b'3.8' b'1.1' b'versicolor']\n",
      " [b'6.5' b'3.2' b'5.1' b'2' b'virginica']\n",
      " [b'4.8' b'3.4' b'1.9' b'0.2' b'setosa']\n",
      " [b'5' b'3.5' b'1.6' b'0.6' b'setosa']\n",
      " [b'6.7' b'3.3' b'5.7' b'2.1' b'virginica']\n",
      " [b'6.5' b'3.2' b'5.1' b'2' b'virginica']\n",
      " [b'4.9' b'3.6' b'1.4' b'0.1' b'setosa']\n",
      " [b'5.5' b'3.5' b'1.3' b'0.2' b'setosa']\n",
      " [b'7.3' b'2.9' b'6.3' b'1.8' b'virginica']\n",
      " [b'6.2' b'3.4' b'5.4' b'2.3' b'virginica']\n",
      " [b'5.2' b'3.5' b'1.5' b'0.2' b'setosa']\n",
      " [b'5.1' b'3.8' b'1.6' b'0.2' b'setosa']\n",
      " [b'5' b'3.2' b'1.2' b'0.2' b'setosa']\n",
      " [b'6.8' b'2.8' b'4.8' b'1.4' b'versicolor']\n",
      " [b'6.2' b'3.4' b'5.4' b'2.3' b'virginica']\n",
      " [b'6' b'2.9' b'4.5' b'1.5' b'versicolor']\n",
      " [b'5' b'3.6' b'1.4' b'0.2' b'setosa']\n",
      " [b'6.4' b'2.8' b'5.6' b'2.1' b'virginica']\n",
      " [b'7.1' b'3' b'5.9' b'2.1' b'virginica']\n",
      " [b'6.5' b'3' b'5.8' b'2.2' b'virginica']\n",
      " [b'5.6' b'2.9' b'3.6' b'1.3' b'versicolor']\n",
      " [b'6.7' b'3' b'5.2' b'2.3' b'virginica']\n",
      " [b'6.7' b'3.1' b'4.4' b'1.4' b'versicolor']\n",
      " [b'7.7' b'3' b'6.1' b'2.3' b'virginica']\n",
      " [b'6.7' b'3.3' b'5.7' b'2.1' b'virginica']\n",
      " [b'6.5' b'3' b'5.8' b'2.2' b'virginica']\n",
      " [b'5.7' b'2.8' b'4.1' b'1.3' b'versicolor']\n",
      " [b'5.6' b'3' b'4.5' b'1.5' b'versicolor']\n",
      " [b'6.7' b'3.1' b'5.6' b'2.4' b'virginica']\n",
      " [b'5.8' b'4' b'1.2' b'0.2' b'setosa']\n",
      " [b'5.1' b'3.8' b'1.5' b'0.3' b'setosa']\n",
      " [b'6.7' b'3.1' b'4.7' b'1.5' b'versicolor']\n",
      " [b'6.6' b'2.9' b'4.6' b'1.3' b'versicolor']\n",
      " [b'6.3' b'2.5' b'4.9' b'1.5' b'versicolor']\n",
      " [b'6.4' b'2.8' b'5.6' b'2.1' b'virginica']\n",
      " [b'5.4' b'3' b'4.5' b'1.5' b'versicolor']]\n",
      "[2 3 3 2 1 2 1 2 3 1 3 3 1 1 3 1 2 2 2 2 3 3 1 1 2 3 1 1 3 3 1 1 3 3 1 1 1\n",
      " 2 3 2 1 3 3 3 2 3 2 3 3 3 2 2 3 1 1 2 2 2 3 2]\n",
      "[[b'5.5' b'2.3' b'4' b'1.3' b'versicolor']\n",
      " [b'6.1' b'2.6' b'5.6' b'1.4' b'virginica']\n",
      " [b'4.6' b'3.1' b'1.5' b'0.2' b'setosa']\n",
      " [b'4.3' b'3' b'1.1' b'0.1' b'setosa']\n",
      " [b'5.1' b'3.4' b'1.5' b'0.2' b'setosa']\n",
      " [b'6.4' b'2.7' b'5.3' b'1.9' b'virginica']\n",
      " [b'6' b'2.2' b'4' b'1' b'versicolor']\n",
      " [b'5.1' b'3.8' b'1.5' b'0.3' b'setosa']\n",
      " [b'5.8' b'4' b'1.2' b'0.2' b'setosa']\n",
      " [b'7.7' b'3' b'6.1' b'2.3' b'virginica']\n",
      " [b'6' b'2.7' b'5.1' b'1.6' b'versicolor']\n",
      " [b'4.9' b'3.1' b'1.5' b'0.2' b'setosa']\n",
      " [b'4.5' b'2.3' b'1.3' b'0.3' b'setosa']\n",
      " [b'5.5' b'2.3' b'4' b'1.3' b'versicolor']\n",
      " [b'5.5' b'3.5' b'1.3' b'0.2' b'setosa']\n",
      " [b'6.4' b'2.7' b'5.3' b'1.9' b'virginica']\n",
      " [b'5' b'3.6' b'1.4' b'0.2' b'setosa']\n",
      " [b'5.8' b'2.7' b'4.1' b'1' b'versicolor']\n",
      " [b'4.6' b'3.6' b'1' b'0.2' b'setosa']\n",
      " [b'6.4' b'3.2' b'4.5' b'1.5' b'versicolor']\n",
      " [b'5.1' b'3.3' b'1.7' b'0.5' b'setosa']\n",
      " [b'4.9' b'3.1' b'1.5' b'0.2' b'setosa']\n",
      " [b'5.8' b'2.8' b'5.1' b'2.4' b'virginica']\n",
      " [b'4.3' b'3' b'1.1' b'0.1' b'setosa']\n",
      " [b'5' b'3.5' b'1.3' b'0.3' b'setosa']\n",
      " [b'6.3' b'2.9' b'5.6' b'1.8' b'virginica']\n",
      " [b'5.1' b'3.3' b'1.7' b'0.5' b'setosa']\n",
      " [b'6.8' b'3.2' b'5.9' b'2.3' b'virginica']\n",
      " [b'6.9' b'3.1' b'5.4' b'2.1' b'virginica']\n",
      " [b'4.7' b'3.2' b'1.3' b'0.2' b'setosa']\n",
      " [b'6.4' b'3.2' b'5.3' b'2.3' b'virginica']\n",
      " [b'7.1' b'3' b'5.9' b'2.1' b'virginica']\n",
      " [b'5' b'3.6' b'1.4' b'0.2' b'setosa']\n",
      " [b'5.7' b'3' b'4.2' b'1.2' b'versicolor']\n",
      " [b'5' b'3.6' b'1.4' b'0.2' b'setosa']\n",
      " [b'4.9' b'2.4' b'3.3' b'1' b'versicolor']\n",
      " [b'4.6' b'3.4' b'1.4' b'0.3' b'setosa']\n",
      " [b'6.7' b'3.3' b'5.7' b'2.1' b'virginica']\n",
      " [b'6.8' b'3' b'5.5' b'2.1' b'virginica']\n",
      " [b'6.4' b'2.8' b'5.6' b'2.2' b'virginica']\n",
      " [b'5.1' b'3.5' b'1.4' b'0.2' b'setosa']\n",
      " [b'7.7' b'3.8' b'6.7' b'2.2' b'virginica']\n",
      " [b'4.3' b'3' b'1.1' b'0.1' b'setosa']\n",
      " [b'6' b'3' b'4.8' b'1.8' b'virginica']\n",
      " [b'6.3' b'2.5' b'4.9' b'1.5' b'versicolor']\n",
      " [b'5.1' b'2.5' b'3' b'1.1' b'versicolor']\n",
      " [b'5.8' b'2.6' b'4' b'1.2' b'versicolor']\n",
      " [b'5.5' b'4.2' b'1.4' b'0.2' b'setosa']\n",
      " [b'7.7' b'3' b'6.1' b'2.3' b'virginica']\n",
      " [b'5.2' b'3.4' b'1.4' b'0.2' b'setosa']\n",
      " [b'5.7' b'2.8' b'4.5' b'1.3' b'versicolor']\n",
      " [b'5.7' b'3.8' b'1.7' b'0.3' b'setosa']\n",
      " [b'7.9' b'3.8' b'6.4' b'2' b'virginica']\n",
      " [b'6.5' b'3' b'5.2' b'2' b'virginica']\n",
      " [b'7.7' b'2.6' b'6.9' b'2.3' b'virginica']\n",
      " [b'6.3' b'3.3' b'6' b'2.5' b'virginica']\n",
      " [b'7' b'3.2' b'4.7' b'1.4' b'versicolor']\n",
      " [b'6.3' b'2.7' b'4.9' b'1.8' b'virginica']\n",
      " [b'5.4' b'3.7' b'1.5' b'0.2' b'setosa']\n",
      " [b'6.4' b'2.7' b'5.3' b'1.9' b'virginica']]\n",
      "[2 3 1 1 1 3 2 1 1 3 2 1 1 2 1 3 1 2 1 2 1 1 3 1 1 3 1 3 3 1 3 3 1 2 1 2 1\n",
      " 3 3 3 1 3 1 3 2 2 2 1 3 1 2 1 3 3 3 3 2 3 1 3]\n",
      "[[b'6.2' b'2.9' b'4.3' b'1.3' b'versicolor']\n",
      " [b'6.1' b'2.9' b'4.7' b'1.4' b'versicolor']\n",
      " [b'4.6' b'3.2' b'1.4' b'0.2' b'setosa']\n",
      " [b'4.4' b'3.2' b'1.3' b'0.2' b'setosa']\n",
      " [b'5.6' b'2.5' b'3.9' b'1.1' b'versicolor']\n",
      " [b'6.5' b'3.2' b'5.1' b'2' b'virginica']\n",
      " [b'6.9' b'3.1' b'4.9' b'1.5' b'versicolor']\n",
      " [b'7.3' b'2.9' b'6.3' b'1.8' b'virginica']\n",
      " [b'6' b'2.9' b'4.5' b'1.5' b'versicolor']\n",
      " [b'6.9' b'3.1' b'5.1' b'2.3' b'virginica']\n",
      " [b'5' b'3.4' b'1.5' b'0.2' b'setosa']\n",
      " [b'5.2' b'3.4' b'1.4' b'0.2' b'setosa']\n",
      " [b'6.4' b'2.9' b'4.3' b'1.3' b'versicolor']\n",
      " [b'6.2' b'2.8' b'4.8' b'1.8' b'virginica']\n",
      " [b'6.3' b'3.3' b'6' b'2.5' b'virginica']\n",
      " [b'5.2' b'4.1' b'1.5' b'0.1' b'setosa']\n",
      " [b'6.7' b'3' b'5' b'1.7' b'versicolor']\n",
      " [b'6.3' b'2.5' b'5' b'1.9' b'virginica']\n",
      " [b'4.5' b'2.3' b'1.3' b'0.3' b'setosa']\n",
      " [b'6.8' b'2.8' b'4.8' b'1.4' b'versicolor']\n",
      " [b'5' b'3.6' b'1.4' b'0.2' b'setosa']\n",
      " [b'4.4' b'3' b'1.3' b'0.2' b'setosa']\n",
      " [b'4.4' b'2.9' b'1.4' b'0.2' b'setosa']\n",
      " [b'5.6' b'2.9' b'3.6' b'1.3' b'versicolor']\n",
      " [b'5.1' b'3.3' b'1.7' b'0.5' b'setosa']\n",
      " [b'4.9' b'3.1' b'1.5' b'0.1' b'setosa']\n",
      " [b'4.5' b'2.3' b'1.3' b'0.3' b'setosa']\n",
      " [b'5.4' b'3.9' b'1.3' b'0.4' b'setosa']\n",
      " [b'7.2' b'3' b'5.8' b'1.6' b'virginica']\n",
      " [b'6' b'3.4' b'4.5' b'1.6' b'versicolor']\n",
      " [b'5' b'3.2' b'1.2' b'0.2' b'setosa']\n",
      " [b'5.4' b'3.4' b'1.7' b'0.2' b'setosa']\n",
      " [b'6' b'2.2' b'4' b'1' b'versicolor']\n",
      " [b'4.6' b'3.6' b'1' b'0.2' b'setosa']\n",
      " [b'5.1' b'3.8' b'1.6' b'0.2' b'setosa']\n",
      " [b'6.2' b'2.2' b'4.5' b'1.5' b'versicolor']\n",
      " [b'6.9' b'3.1' b'5.4' b'2.1' b'virginica']\n",
      " [b'6.3' b'2.5' b'4.9' b'1.5' b'versicolor']\n",
      " [b'5.9' b'3' b'4.2' b'1.5' b'versicolor']\n",
      " [b'4.9' b'3' b'1.4' b'0.2' b'setosa']\n",
      " [b'5.3' b'3.7' b'1.5' b'0.2' b'setosa']\n",
      " [b'5.2' b'3.5' b'1.5' b'0.2' b'setosa']\n",
      " [b'4.8' b'3.4' b'1.9' b'0.2' b'setosa']\n",
      " [b'4.9' b'3.1' b'1.5' b'0.2' b'setosa']\n",
      " [b'5.1' b'3.3' b'1.7' b'0.5' b'setosa']\n",
      " [b'6.3' b'3.4' b'5.6' b'2.4' b'virginica']\n",
      " [b'6.8' b'3.2' b'5.9' b'2.3' b'virginica']\n",
      " [b'7.1' b'3' b'5.9' b'2.1' b'virginica']\n",
      " [b'6.5' b'3.2' b'5.1' b'2' b'virginica']\n",
      " [b'4.4' b'3.2' b'1.3' b'0.2' b'setosa']\n",
      " [b'6' b'2.2' b'5' b'1.5' b'virginica']\n",
      " [b'7.2' b'3.2' b'6' b'1.8' b'virginica']\n",
      " [b'5.1' b'2.5' b'3' b'1.1' b'versicolor']\n",
      " [b'6.9' b'3.2' b'5.7' b'2.3' b'virginica']\n",
      " [b'6.5' b'3.2' b'5.1' b'2' b'virginica']\n",
      " [b'6.7' b'3.1' b'4.4' b'1.4' b'versicolor']\n",
      " [b'4.8' b'3' b'1.4' b'0.1' b'setosa']\n",
      " [b'4.6' b'3.1' b'1.5' b'0.2' b'setosa']\n",
      " [b'5.4' b'3.7' b'1.5' b'0.2' b'setosa']\n",
      " [b'5.2' b'2.7' b'3.9' b'1.4' b'versicolor']]\n",
      "[2 2 1 1 2 3 2 3 2 3 1 1 2 3 3 1 2 3 1 2 1 1 1 2 1 1 1 1 3 2 1 1 2 1 1 2 3\n",
      " 2 2 1 1 1 1 1 1 3 3 3 3 1 3 3 2 3 3 2 1 1 1 2]\n",
      "[[b'6.4' b'2.8' b'5.6' b'2.1' b'virginica']\n",
      " [b'5.7' b'4.4' b'1.5' b'0.4' b'setosa']\n",
      " [b'4.4' b'3.2' b'1.3' b'0.2' b'setosa']\n",
      " [b'4.6' b'3.1' b'1.5' b'0.2' b'setosa']\n",
      " [b'6.9' b'3.1' b'5.4' b'2.1' b'virginica']\n",
      " [b'5.6' b'2.9' b'3.6' b'1.3' b'versicolor']\n",
      " [b'5.8' b'2.7' b'3.9' b'1.2' b'versicolor']\n",
      " [b'7.2' b'3.6' b'6.1' b'2.5' b'virginica']\n",
      " [b'5.7' b'2.9' b'4.2' b'1.3' b'versicolor']\n",
      " [b'5.4' b'3' b'4.5' b'1.5' b'versicolor']\n",
      " [b'7.6' b'3' b'6.6' b'2.1' b'virginica']\n",
      " [b'7.7' b'3.8' b'6.7' b'2.2' b'virginica']\n",
      " [b'4.5' b'2.3' b'1.3' b'0.3' b'setosa']\n",
      " [b'5' b'2.3' b'3.3' b'1' b'versicolor']\n",
      " [b'7.7' b'3' b'6.1' b'2.3' b'virginica']\n",
      " [b'6.4' b'3.1' b'5.5' b'1.8' b'virginica']\n",
      " [b'6.3' b'2.3' b'4.4' b'1.3' b'versicolor']\n",
      " [b'5.5' b'2.6' b'4.4' b'1.2' b'versicolor']\n",
      " [b'5.2' b'3.5' b'1.5' b'0.2' b'setosa']\n",
      " [b'5.2' b'2.7' b'3.9' b'1.4' b'versicolor']\n",
      " [b'6.7' b'2.5' b'5.8' b'1.8' b'virginica']\n",
      " [b'5' b'3.4' b'1.6' b'0.4' b'setosa']\n",
      " [b'4.4' b'3.2' b'1.3' b'0.2' b'setosa']\n",
      " [b'5' b'2.3' b'3.3' b'1' b'versicolor']\n",
      " [b'5.5' b'2.4' b'3.7' b'1' b'versicolor']\n",
      " [b'5.7' b'2.6' b'3.5' b'1' b'versicolor']\n",
      " [b'5.4' b'3.7' b'1.5' b'0.2' b'setosa']\n",
      " [b'6.2' b'2.9' b'4.3' b'1.3' b'versicolor']\n",
      " [b'5.7' b'2.8' b'4.1' b'1.3' b'versicolor']\n",
      " [b'6' b'2.7' b'5.1' b'1.6' b'versicolor']\n",
      " [b'6.9' b'3.1' b'5.4' b'2.1' b'virginica']\n",
      " [b'5.1' b'3.3' b'1.7' b'0.5' b'setosa']\n",
      " [b'6.9' b'3.1' b'5.4' b'2.1' b'virginica']\n",
      " [b'5.1' b'3.8' b'1.5' b'0.3' b'setosa']\n",
      " [b'7.7' b'2.8' b'6.7' b'2' b'virginica']\n",
      " [b'6.4' b'2.8' b'5.6' b'2.2' b'virginica']\n",
      " [b'5.4' b'3.9' b'1.7' b'0.4' b'setosa']\n",
      " [b'5.5' b'2.5' b'4' b'1.3' b'versicolor']\n",
      " [b'5.8' b'2.8' b'5.1' b'2.4' b'virginica']\n",
      " [b'5' b'2.3' b'3.3' b'1' b'versicolor']\n",
      " [b'5.7' b'2.8' b'4.5' b'1.3' b'versicolor']\n",
      " [b'6.2' b'3.4' b'5.4' b'2.3' b'virginica']\n",
      " [b'5' b'2' b'3.5' b'1' b'versicolor']\n",
      " [b'4.9' b'3.6' b'1.4' b'0.1' b'setosa']\n",
      " [b'6.3' b'2.5' b'4.9' b'1.5' b'versicolor']\n",
      " [b'6.5' b'2.8' b'4.6' b'1.5' b'versicolor']\n",
      " [b'5.8' b'2.7' b'5.1' b'1.9' b'virginica']\n",
      " [b'5.4' b'3' b'4.5' b'1.5' b'versicolor']\n",
      " [b'5.9' b'3.2' b'4.8' b'1.8' b'versicolor']\n",
      " [b'5.8' b'4' b'1.2' b'0.2' b'setosa']\n",
      " [b'6.8' b'3' b'5.5' b'2.1' b'virginica']\n",
      " [b'6.3' b'2.8' b'5.1' b'1.5' b'virginica']\n",
      " [b'6.8' b'3.2' b'5.9' b'2.3' b'virginica']\n",
      " [b'4.6' b'3.1' b'1.5' b'0.2' b'setosa']\n",
      " [b'4.7' b'3.2' b'1.6' b'0.2' b'setosa']\n",
      " [b'5.7' b'2.5' b'5' b'2' b'virginica']\n",
      " [b'6.3' b'2.3' b'4.4' b'1.3' b'versicolor']\n",
      " [b'6.5' b'3' b'5.5' b'1.8' b'virginica']\n",
      " [b'6.6' b'3' b'4.4' b'1.4' b'versicolor']\n",
      " [b'5' b'3.5' b'1.3' b'0.3' b'setosa']]\n",
      "[3 1 1 1 3 2 2 3 2 2 3 3 1 2 3 3 2 2 1 2 3 1 1 2 2 2 1 2 2 2 3 1 3 1 3 3 1\n",
      " 2 3 2 2 3 2 1 2 2 3 2 2 1 3 3 3 1 1 3 2 3 2 1]\n"
     ]
    }
   ],
   "source": [
    "init_op = tf.global_variables_initializer()\n",
    "local_init_op = tf.local_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    sess.run(local_init_op)\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    try:\n",
    "        for _ in range(6):\n",
    "            example, label = sess.run([x_test, y_test])\n",
    "            print (example)\n",
    "            print (label)\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print ('Done reading')\n",
    "    finally:\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "        sess.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## picture\n",
    "import matplotlib.pyplot as plt\n",
    "path = \"/Users/lixing/jupyter/Build ML Projects with TF/Chap01_bak/\"\n",
    "file_path = path + \"00.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_queue = tf.train.string_input_producer(\n",
    "    tf.train.match_filenames_once(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = tf.WholeFileReader()\n",
    "key, value = reader.read(filename_queue)\n",
    "image = tf.image.decode_jpeg(value)\n",
    "\n",
    "flipImageUpDown = tf.image.flip_up_down(image)\n",
    "flipImageLeftRight = tf.image.flip_left_right(image)\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "local_init_op = tf.local_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[234 254 253]\n",
      "  [234 254 253]\n",
      "  [234 254 253]\n",
      "  ...\n",
      "  [  7  28  11]\n",
      "  [  8  36  11]\n",
      "  [  0  35   5]]\n",
      "\n",
      " [[234 254 253]\n",
      "  [234 254 253]\n",
      "  [234 254 253]\n",
      "  ...\n",
      "  [  0  18   0]\n",
      "  [  0  26   1]\n",
      "  [  0  25   0]]\n",
      "\n",
      " [[234 254 253]\n",
      "  [234 254 253]\n",
      "  [234 254 253]\n",
      "  ...\n",
      "  [  2  19   1]\n",
      "  [  1  25   3]\n",
      "  [  0  25   0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[251 253 252]\n",
      "  [252 252 252]\n",
      "  [254 254 252]\n",
      "  ...\n",
      "  [254 254 254]\n",
      "  [254 254 254]\n",
      "  [254 254 254]]\n",
      "\n",
      " [[252 254 253]\n",
      "  [254 255 255]\n",
      "  [254 255 255]\n",
      "  ...\n",
      "  [254 254 254]\n",
      "  [254 254 254]\n",
      "  [254 254 254]]\n",
      "\n",
      " [[254 255 255]\n",
      "  [251 253 252]\n",
      "  [252 254 253]\n",
      "  ...\n",
      "  [254 254 254]\n",
      "  [254 254 254]\n",
      "  [254 254 254]]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    try:\n",
    "        sess.run(init_op)\n",
    "        sess.run(local_init_op)\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(coord=coord, sess=sess)\n",
    "        up_down_image = tf.image.encode_jpeg(flipImageUpDown)\n",
    "        left_right_image = tf.image.encode_jpeg(flipImageLeftRight)\n",
    "        example = sess.run(flipImageLeftRight)\n",
    "        print(example)  ## 逐行 RGB值\n",
    "        \n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print ('Done reading')\n",
    "    finally:\n",
    "        f = open(path + \"left_right.jpg\", \"wb+\")\n",
    "        f.write(left_right_image.eval(session=sess))\n",
    "        f.close()\n",
    "        \n",
    "        f = open(path + \"up_down_image.jpg\", \"wb+\")\n",
    "        f.write(up_down_image.eval(session=sess))\n",
    "        f.close()\n",
    "        #plt.imshow(flipImageLeftRight.eval(session=sess))\n",
    "        #plt.imshow(flipImageUpDown.eval(session=sess))\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "        sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
